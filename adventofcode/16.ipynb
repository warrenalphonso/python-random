{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acute-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "correct-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules, my_ticket, tickets = data(16, parser=lambda s: s.split(\"\\n\"), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "given-tumor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['nearby tickets:',\n",
       "  '279,705,188,357,892,488,741,247,572,176,760,306,410,861,507,906,179,501,808,245'],\n",
       " ['your ticket:',\n",
       "  '73,101,67,97,149,53,89,113,79,131,71,127,137,61,139,103,83,107,109,59'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets[:2], my_ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-affairs",
   "metadata": {},
   "source": [
    "Create one `tickets` list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "charitable-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove text and combine\n",
    "tickets.pop(0)\n",
    "# Convert to lists of ints \n",
    "tickets = [[int(n) for n in row.split(\",\")] for row in tickets]\n",
    "\n",
    "# Remove text \n",
    "my_ticket = [int(n) for n in my_ticket[1].split(\",\")] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-dakota",
   "metadata": {},
   "source": [
    "Create one `rules` dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "resident-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['departure location: 26-715 or 727-972',\n",
       " 'departure station: 45-164 or 175-960',\n",
       " 'departure platform: 43-247 or 270-972']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "simple-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rule(rule: str) -> tuple[str, list[tuple]]:\n",
    "    \"\"\"Parse rules into bounds.\"\"\" \n",
    "    name, rest = rule.split(\":\")\n",
    "        \n",
    "    bounds = []\n",
    "    for bound in rest.strip().split(\" or \"):\n",
    "        minimum, maximum = bound.split(\"-\")\n",
    "        bounds.append((int(minimum), int(maximum)))\n",
    "    \n",
    "    return (name, bounds)\n",
    "\n",
    "assert parse_rule(\"departure location: 26-715 or 727-972\") == ('departure location', [(26, 715), (727, 972)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assisted-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = dict(parse_rule(rule) for rule in rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "perceived-evolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'departure location': [(26, 715), (727, 972)],\n",
       " 'departure station': [(45, 164), (175, 960)],\n",
       " 'departure platform': [(43, 247), (270, 972)],\n",
       " 'departure track': [(25, 306), (330, 949)],\n",
       " 'departure date': [(26, 635), (660, 961)],\n",
       " 'departure time': [(42, 773), (793, 961)],\n",
       " 'arrival location': [(28, 928), (943, 952)],\n",
       " 'arrival station': [(36, 593), (613, 966)],\n",
       " 'arrival platform': [(33, 280), (297, 951)],\n",
       " 'arrival track': [(44, 358), (371, 974)],\n",
       " 'class': [(39, 815), (839, 955)],\n",
       " 'duration': [(39, 573), (589, 959)],\n",
       " 'price': [(49, 846), (865, 962)],\n",
       " 'route': [(30, 913), (924, 954)],\n",
       " 'row': [(29, 865), (890, 965)],\n",
       " 'seat': [(44, 667), (683, 969)],\n",
       " 'train': [(32, 473), (482, 969)],\n",
       " 'type': [(40, 424), (432, 953)],\n",
       " 'wagon': [(49, 156), (164, 960)],\n",
       " 'zone': [(34, 521), (534, 971)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-participant",
   "metadata": {},
   "source": [
    "**Part 1:** Find the error rate, the sum of invalid values for any field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pediatric-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def within(val: int, minimum: int, maximum: int) -> bool:\n",
    "    \"\"\"Return whether val is within (minimum, maximum).\"\"\"\n",
    "    return minimum <= val <= maximum\n",
    "\n",
    "assert within(972, 26, 1715)\n",
    "assert not within(3, 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "electrical-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [field for ticket in tickets \n",
    "                for field in ticket \n",
    "                if not any(within(field, *bound) \n",
    "                           for bounds in rules.values() \n",
    "                           for bound in bounds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "typical-darkness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21081"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-northern",
   "metadata": {},
   "source": [
    "**Part 1, Improved:** The main thing I need to clean up is converting a list of rule strings into a dictionary of name to ranges. My way of using `ChainMap` seems incomprehensible. Updated that above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-amendment",
   "metadata": {},
   "source": [
    "**Part 1, Norvig:** Norvig created a class called `Sets` which inherits from `tuple` and is initialized with a list of tuples. It implements `in` which checks if an element is in any of the sets it holds. That's a pretty neat idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifth-musician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21081"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sets(tuple):\n",
    "    def __contains__(self, v):\n",
    "        return any(within(v, *bound) for bound in self)\n",
    "    \n",
    "for k, v in rules.items():\n",
    "    rules[k] = Sets(v)\n",
    "    \n",
    "assert 45 in rules[\"seat\"]\n",
    "assert 500 in rules[\"type\"]\n",
    "assert 1000 not in rules[\"row\"]\n",
    "\n",
    "errors = [field for ticket in tickets \n",
    "                for field in ticket \n",
    "                if not any(field in bounds for bounds in rules.values())]\n",
    "\n",
    "sum(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-grave",
   "metadata": {},
   "source": [
    "**Part 2:** Discard the invalid tickets. Determine the order of the fields on each ticket, assuming the rest of the tickets are valid.  Multiply the six fields on my ticket that start with the word \"departure\".\n",
    "\n",
    "My strategy is to create a mapping of index to set of possible fields. Then I'll iterate through that, on each step choose the index with fewest possible fields and assign it one, then remove that field from any other indices' possible fields, and repepat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chief-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = [my_ticket, *tickets]\n",
    "valid_tickets = [ticket \n",
    "                         for ticket in tickets\n",
    "                         if all(any(field in bounds for bounds in rules.values()) for field in ticket)]\n",
    "\n",
    "assert len(valid_tickets) == len(tickets) - len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "creative-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_fields = {i: set(field_name \n",
    "                          for field_name, sets in rules.items()\n",
    "                          if all(ticket[i] in sets\n",
    "                                 for ticket in valid_tickets)) \n",
    "                   for i in range(len(valid_tickets[0]))}\n",
    "\n",
    "field_assignments = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "personal-diagnosis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'route',\n",
       " 12: 'seat',\n",
       " 4: 'arrival station',\n",
       " 5: 'duration',\n",
       " 1: 'arrival track',\n",
       " 8: 'train',\n",
       " 15: 'class',\n",
       " 19: 'departure track',\n",
       " 13: 'departure time',\n",
       " 7: 'departure platform',\n",
       " 16: 'departure date',\n",
       " 14: 'departure station',\n",
       " 2: 'departure location',\n",
       " 17: 'price',\n",
       " 11: 'wagon',\n",
       " 18: 'zone',\n",
       " 9: 'row',\n",
       " 6: 'arrival platform',\n",
       " 3: 'type',\n",
       " 10: 'arrival location'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    if not possible_fields:\n",
    "        break \n",
    "\n",
    "    # Choose next index to assign \n",
    "    next_index = min(possible_fields, \n",
    "                     key=lambda k: len(possible_fields[k]))\n",
    "    \n",
    "    # Ensure it's still possible to find a matching \n",
    "    if not possible_fields[next_index]:\n",
    "        raise ValueError(f\"Finding a matching is impossible. No fields left for index {next_index}.\")\n",
    "    \n",
    "    # Assign next_index a field name \n",
    "    assigned_field = possible_fields[next_index].pop()\n",
    "    field_assignments[next_index] = assigned_field\n",
    "    \n",
    "    # Remove assigned field from all other possible_fields \n",
    "    for i in possible_fields:\n",
    "        possible_fields[i] -= { assigned_field }\n",
    "    \n",
    "    # Remove next_index from possible_fields \n",
    "    del possible_fields[next_index]\n",
    "    \n",
    "field_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "broad-insider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314360510573"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = 1\n",
    "for k, v in field_assignments.items():\n",
    "    if \"departure\" in v:\n",
    "        prod *= my_ticket[k]\n",
    "        \n",
    "prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-backup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
